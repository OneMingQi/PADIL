meta_data:
  script_path: scripts/PADIL.py
  exp_name: PADIL_halfcheetah
  description: PADIL
  num_workers: 10
  using_gpus: true
# -----------------------------------------------------------------------------
variables:
  adv_irl_params:
    grad_pen_weight: [ 4.0 ]
  reward_scale: [ 2.0 ]
  # seed: [ 0, 1, 2, 3, 4 ]
  seed: [ 0 ]
  traj_num: [ 1 ]
# -----------------------------------------------------------------------------
constants:
  expert_name: 'halfcheetah_sac'
  expert_idx: 0
  traj_num: 16
  scale_env_with_demo_stats: false
  minmax_env_with_demo_stats: false

  diffusion_n_timesteps: 20

  disc_num_blocks: 2
  disc_hid_dim: 128
  disc_hid_act: tanh
  disc_use_bn: false
  disc_clamp_magnitude: 10.0

  policy_net_size: 256
  policy_num_hidden_layers: 2

  adv_irl_params:
    mode: 'PADIL'
    state_only: false

    num_epochs: 50
    num_steps_per_epoch: 10000
    num_steps_between_train_calls: 1000
    max_path_length: 1000
    min_steps_before_training: 5000

    eval_deterministic: true
    num_steps_per_eval: 10000
    
    replay_buffer_size: 1000000
    no_terminal: true
    eval_no_terminal: false
    wrap_absorbing: false

    num_update_loops_per_train_call: 1000
    num_disc_updates_per_loop_iter: 1
    num_policy_updates_per_loop_iter: 1

    disc_lr: 0.0003
    disc_momentum: 0.9
    use_grad_pen: true
    disc_optim_batch_size: 256
    policy_optim_batch_size: 256
    policy_optim_batch_size_from_expert: 0

    save_best: true
    save_epoch: false
    freq_saving: 20
    save_replay_buffer: false

  env_specs:
    env_name: 'halfcheetah'
    env_kwargs: { }
    env_num: 1
    disc_ddpm: false
    
  diffusion_params:
    gamma: 0.99
    tau: 0.005
    update_actor_target_every: 1
    policy_type: 'Diffusion'
    beta_schedule: 'cosine'
    diffusion_lr: 0.0003
    critic_lr: 0.0003
    action_lr: 0.03
    noise_ratio: 1.0
    action_gradient_steps: 10
    ratio: 0.1
    ac_grad_norm: 2.0
